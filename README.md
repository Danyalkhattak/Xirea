# Xirea

<p align="center">
  <img src="app/src/main/res/mipmap-xxxhdpi/ic_launcher_round.webp" alt="Xirea Logo" width="120"/>
</p>

<p align="center">
  <b>Offline AI Chat Assistant for Android</b>
</p>

<p align="center">
  <a href="#features">Features</a> â€¢
  <a href="#screenshots">Screenshots</a> â€¢
  <a href="#installation">Installation</a> â€¢
  <a href="#building">Building</a> â€¢
  <a href="#tech-stack">Tech Stack</a> â€¢
  <a href="#license">License</a>
</p>

---

## Overview

**Xirea** is a fully offline AI chat assistant that runs lightweight language models directly on your Android device. No internet required, no API keys, no data leaving your phone â€” your conversations stay completely private.

Powered by [llama.cpp](https://github.com/ggerganov/llama.cpp) for efficient on-device inference with GGUF models.

---

## Features

- ğŸ”’ **100% Offline** â€” All AI processing happens on-device
- ğŸš€ **Fast Inference** â€” Optimized for mobile with dynamic RAM scaling
- ğŸ’¬ **Chat History** â€” Persistent local storage with Room database
- ğŸ“¥ **Model Management** â€” Download, switch, and delete AI models
- ğŸŒ™ **Dark Mode** â€” Beautiful Material3 light and dark themes
- ğŸ“± **Modern UI** â€” Built with Jetpack Compose
- ğŸ” **Privacy First** â€” No data collection, no servers, no tracking

---

## Screenshots

| Home | Chat | Models | Settings |
|------|------|--------|----------|
| ![Home](screenshots/home.jpeg) | ![Chat](screenshots/chat.jpeg) | ![Models](screenshots/models.jpeg) | ![Settings](screenshots/settings.jpeg) |

---

## Installation

### Requirements

- Android 8.0+ (API 26)
- ARM64 device (arm64-v8a)
- At least 4GB RAM recommended
- Storage space for AI models (500MB - 4GB per model)

### Download

Download the latest APK from the [Releases](https://github.com/Danyalkhattak/xirea/releases) page.

---

## Building

### Prerequisites

- Android Studio Hedgehog or newer
- Android NDK 29.0.14206865
- CMake 3.22.1
- JDK 17

### Steps

1. **Clone the repository**
   ```bash
   git clone https://github.com/Danyalkhattak/xirea.git
   cd xirea
   ```

2. **Open in Android Studio**
   - Open the project folder in Android Studio
   - Wait for Gradle sync to complete

3. **Build Debug APK**
   ```bash
   ./gradlew assembleDebug
   ```

4. **Build Release APK** (requires signing keystore)
   ```bash
   ./gradlew assembleRelease
   ```

The APK will be generated at `app/build/outputs/apk/`

---

## Tech Stack

| Component | Technology |
|-----------|------------|
| **Language** | Kotlin |
| **UI Framework** | Jetpack Compose |
| **AI Engine** | llama.cpp (C++) |
| **Database** | Room |
| **Architecture** | MVVM |
| **Async** | Kotlin Coroutines + Flow |
| **DI** | Manual (lightweight) |
| **Theme** | Material3 |

---

## Supported Models

Xirea works with GGUF format models. Recommended models for mobile:

| Model | Size | RAM Required |
|-------|------|--------------|
| Qwen2.5 0.5B Q4 | ~400MB | 4GB |
| Qwen2.5 1.5B Q4 | ~1GB | 6GB |
| Llama 3.2 1B Q4 | ~700MB | 4GB |
| Phi-3 Mini Q4 | ~2GB | 8GB |
| Gemma 2B Q4 | ~1.5GB | 6GB |

---

## Performance Optimization

Xirea automatically optimizes for your device:

| Device RAM | Context Size | Batch Size |
|------------|--------------|------------|
| 4GB | 512 | 128 |
| 6GB | 768 | 256 |
| 8GB | 1024 | 256 |
| 12GB+ | 2048 | 512 |

- **CPU-only inference** for maximum compatibility
- **Memory-mapped model loading** for reduced RAM usage
- **Pre-allocated batch buffers** for zero-allocation generation
- **Near-greedy sampling** for faster token generation

---

## Project Structure

```
xirea/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ src/main/
â”‚   â”‚   â”œâ”€â”€ java/com/dannyk/xirea/
â”‚   â”‚   â”‚   â”œâ”€â”€ ai/          # AI engine & llama.cpp wrapper
â”‚   â”‚   â”‚   â”œâ”€â”€ data/        # Room database & repositories
â”‚   â”‚   â”‚   â”œâ”€â”€ service/     # Download service
â”‚   â”‚   â”‚   â””â”€â”€ ui/          # Compose UI screens
â”‚   â”‚   â”œâ”€â”€ cpp/             # Native C++ code
â”‚   â”‚   â”‚   â”œâ”€â”€ llama.cpp/   # llama.cpp library
â”‚   â”‚   â”‚   â””â”€â”€ llama_jni.cpp # JNI bridge
â”‚   â”‚   â””â”€â”€ res/             # Resources
â”‚   â””â”€â”€ build.gradle.kts
â”œâ”€â”€ gradle/
â”‚   â””â”€â”€ libs.versions.toml   # Version catalog
â””â”€â”€ build.gradle.kts
```

---

## Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

1. Fork the repository
2. Create your feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

---

## License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

## Author

**Danyal Khattak**

- GitHub: [@Danyalkhattak](https://github.com/Danyalkhattak)

---

## Acknowledgments

- [llama.cpp](https://github.com/ggerganov/llama.cpp) â€” Excellent C++ inference engine
- [Jetpack Compose](https://developer.android.com/jetpack/compose) â€” Modern Android UI toolkit
- [Material3](https://m3.material.io/) â€” Design system

---

<p align="center">
  Made with â¤ï¸ by Danyal Khattak
</p>
